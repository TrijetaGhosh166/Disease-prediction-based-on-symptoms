{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "import initial modules and libraries"
      ],
      "metadata": {
        "id": "bLCGHaUNfEG-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvvmLoPKb0HF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import shuffle # Import the shuffle function\n",
        "\n",
        "# read the dataset\n",
        "df=pd.read_csv('dataset.csv')\n",
        "df = shuffle(df,random_state=42) # Now you can use the shuffle function\n",
        "df.head()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JyoDX4TNvCkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# row and col\n",
        "df.shape"
      ],
      "metadata": {
        "id": "z9YtEXsBc70m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#columns names\n",
        "df.columns"
      ],
      "metadata": {
        "id": "SGMyvcwxdAG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataset we can see some symptom are writing by using \"-\" ,\n",
        "need to remove those symptoms and white spaces"
      ],
      "metadata": {
        "id": "jYXn5dRGfe3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "\n",
        "    df[col] = df[col].str.replace('_',' ')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "OXRUt4WRctkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# statistical observation\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "ybiWwSz_cw63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the null values and store null_check variable\n",
        "null_check=df.isnull().sum()\n",
        "print(null_check)"
      ],
      "metadata": {
        "id": "8yfAwSeJdL4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count all the null values\n",
        "null_check = df.apply(lambda x: sum(x.isnull())).to_frame(name='count')\n",
        "print(null_check)"
      ],
      "metadata": {
        "id": "WKHP9S9Rd2eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the null values\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.plot(null_check.index, null_check['count'],color='r')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Before removing Null values')\n",
        "plt.xlabel('column names')\n",
        "plt.ylabel('count of null values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "30FWf5MseJcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BfByxTqjgJm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# store columns name in col\n",
        "cols=df.columns\n",
        "cols"
      ],
      "metadata": {
        "id": "v3m7X45Led34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the DataFrame into a 1D array\n",
        "data = df[cols].values.flatten()\n",
        "data"
      ],
      "metadata": {
        "id": "Y8qxKd7tgT1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening a DataFrame into a 1D array simplifies data manipulation and analysis tasks, making it easier to perform operations, work with certain functions, and visualize data effectively."
      ],
      "metadata": {
        "id": "jxBuDyh_jEEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to a Pandas Series and strip whitespace\n",
        "s = pd.Series(data)\n",
        "# Remove leading and trailing whitespace\n",
        "s = s.str.strip()\n"
      ],
      "metadata": {
        "id": "-bWWPftbi7W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code converts the flattened DataFrame values into a Pandas Series and then removes leading and trailing whitespace from the elements in the Series."
      ],
      "metadata": {
        "id": "kBsgE9YZjbs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape the values in series\n",
        "s = s.values.reshape(df.shape)"
      ],
      "metadata": {
        "id": "QvMSEUFJjYmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(s, columns=df.columns)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "hz3xX-Sojr1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fill the missing values with 0\n",
        "df = df.fillna(0)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "oFaPk_KNk3DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see previous where present NAN values all are convert in to 0"
      ],
      "metadata": {
        "id": "6VIlhqFPlTOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Symptom-severity csv\n",
        "df1 = pd.read_csv('Symptom-severity.csv')\n",
        "df1['Symptom'] = df1['Symptom'].str.replace('_',' ')\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "b8sgqHdGlRhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique valu of dataset csv\n",
        "df1['Symptom'].unique()"
      ],
      "metadata": {
        "id": "sn8nyo1WladW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Symptom'].value_counts()"
      ],
      "metadata": {
        "id": "ZK7gOe7rlwHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Disease'].unique()"
      ],
      "metadata": {
        "id": "tYykPNAupyg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "need to replace values in a DataFrame (df)based on a mapping from another DataFrame(df1)"
      ],
      "metadata": {
        "id": "sT_BHiGTmjwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the values of the DataFrame df as a Numpy array\n",
        "values = df.values\n",
        "#retrives unique values from the symptom of df1\n",
        "symptoms = df1['Symptom'].unique()\n",
        "#replace values in the array based on mapping from df1\n",
        "for i in range(len(symptoms)):\n",
        "\n",
        "  values[values == symptoms[i]] = df1[df1['Symptom'] == symptoms[i]]['weight'].values[0]"
      ],
      "metadata": {
        "id": "kvbFkuDql3qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new DataFrame with modified values\n",
        "newdata= pd.DataFrame(values, columns=cols)\n",
        "newdata.head()"
      ],
      "metadata": {
        "id": "6RyOXaY7oXrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace specific values with 0\n",
        "newdata =newdata.replace('dischromic patches', 0)\n",
        "newdata= newdata.replace('spotting urination', 0)\n",
        "df = newdata.replace('foul smell of urine', 0)\n",
        "\n",
        "# Display the first 10 rows of the new DataFrame\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "Pm-ZeuJlobL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# again check null\n",
        "null_check = df.apply(lambda x: sum(x.isnull())).to_frame(name='count')\n",
        "print(null_check)"
      ],
      "metadata": {
        "id": "RENegWsJpDi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now here is no null values are present\n"
      ],
      "metadata": {
        "id": "4Fcbk26gpVAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Symptoms used to identify the disease \",len(df1['Symptom'].unique()))\n",
        "print(\"Diseases that can be identified \",len(df['Disease'].unique()))"
      ],
      "metadata": {
        "id": "QKzREpGupSIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.iloc[:,1:].values\n",
        "labels = df['Disease'].values"
      ],
      "metadata": {
        "id": "aD6R8VqJpt0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train test split (take 80% for train and 20% for test)"
      ],
      "metadata": {
        "id": "BzXlFnqKqIj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, shuffle=True, train_size = 0.80, random_state=42)"
      ],
      "metadata": {
        "id": "TvluZLAFqE2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "JqsD11NsqcER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Disease'].unique()"
      ],
      "metadata": {
        "id": "Fyp3C68MqrEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creat a model of Random Forest Classifier"
      ],
      "metadata": {
        "id": "1Uj3jnkeqkEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows of the NumPy array\n",
        "print(x_train[:5])\n"
      ],
      "metadata": {
        "id": "k0a7ji5yte3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[:10])"
      ],
      "metadata": {
        "id": "pOvw-CtCxT59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[:10])"
      ],
      "metadata": {
        "id": "Eb8yi2lrx_IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data types of x_train\n",
        "print(x_train.dtype)\n"
      ],
      "metadata": {
        "id": "Tbqaf6wYyJbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I9aLeadoz2FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "explore x_train data"
      ],
      "metadata": {
        "id": "CB7i15E8z3EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert x_train to DataFrame for easier manipulation\n",
        "x_train_df = pd.DataFrame(x_train)\n",
        "\n",
        "# Inspect the DataFrame to find non-numeric values\n",
        "print(x_train_df.head())\n",
        "print(x_train_df.dtypes)"
      ],
      "metadata": {
        "id": "QeTqAMavybLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see there is present also object so we cant fir it in model have to convert those non numeric values to numeric values"
      ],
      "metadata": {
        "id": "tDHwwqrWzTYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find unique values to check for non-numeric entries\n",
        "unique_values = pd.unique(x_train_df.values.ravel())\n",
        "print(unique_values)"
      ],
      "metadata": {
        "id": "Z9AJJXkwyv4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace specific non-numeric values with a numeric value (e.g., 0)\n",
        "x_train_df.replace(['dischromic  patches', 'spotting  urination'], 0, inplace=True)\n",
        "\n",
        "# Convert the DataFrame to numeric, coercing errors to NaN (if needed)\n",
        "x_train_df = x_train_df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Fill NaN values with a specific number (e.g., 0)\n",
        "x_train_df.fillna(0, inplace=True)\n",
        "\n",
        "# Convert back to NumPy array\n",
        "x_train = x_train_df.values\n"
      ],
      "metadata": {
        "id": "oPCDxa8ky5hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.dtype)"
      ],
      "metadata": {
        "id": "BuhE1N1WzHha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find unique values to check for non-numeric entries\n",
        "unique_values = pd.unique(x_train_df.values.ravel())\n",
        "print(unique_values)"
      ],
      "metadata": {
        "id": "tj2k1dfvzLL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "explore x_test data"
      ],
      "metadata": {
        "id": "xr1aMLxlz7Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data types of x_test\n",
        "print(x_test.dtype)"
      ],
      "metadata": {
        "id": "uV-fmP4Iz-4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert x_train to DataFrame for easier manipulation\n",
        "x_test_df = pd.DataFrame(x_test)\n",
        "\n",
        "# Inspect the DataFrame to find non-numeric values\n",
        "print(x_test_df.head())\n",
        "print(x_test_df.dtypes)"
      ],
      "metadata": {
        "id": "Ir_tYqby0Dpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find unique values to check for non-numeric entries\n",
        "unique_values = pd.unique(x_test_df.values.ravel())\n",
        "print(unique_values)"
      ],
      "metadata": {
        "id": "n7RAIqIK0O-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace specific non-numeric values with a numeric value (e.g., 0)\n",
        "x_test_df.replace(['dischromic  patches', 'spotting  urination'], 0, inplace=True)\n",
        "\n",
        "# Convert the DataFrame to numeric, coercing errors to NaN (if needed)\n",
        "x_test_df = x_test_df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Fill NaN values with a specific number (e.g., 0)\n",
        "x_test_df.fillna(0, inplace=True)\n",
        "\n",
        "# Convert back to NumPy array\n",
        "x_test = x_test_df.values"
      ],
      "metadata": {
        "id": "6aKkctaI0U89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data types of x_test\n",
        "print(x_test.dtype)"
      ],
      "metadata": {
        "id": "iJfeNSNx0gDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RandomForestClassifier**"
      ],
      "metadata": {
        "id": "RR-gAlbs4-eC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rnd_forest = RandomForestClassifier(random_state=42, max_features='sqrt', n_estimators= 500, max_depth=13)\n",
        "rnd_forest.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "dmG6G1y5zOLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=rnd_forest.predict(x_test)"
      ],
      "metadata": {
        "id": "Pymn0rTfznJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test[0])\n",
        "print(y_pred[0])"
      ],
      "metadata": {
        "id": "vwTRiMzUzwj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "NK1oB6Vk0z2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "id": "JmK5zEKE09NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(conf, index=df['Disease'].unique(), columns=df['Disease'].unique())\n",
        "print('F1-score% =', f1_score(y_test, y_pred, average='macro')*100, '|', 'Accuracy% =', accuracy_score(y_test, y_pred)*100)\n",
        "sns.heatmap(df_cm)"
      ],
      "metadata": {
        "id": "DIgpiqWo0_G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "L5BIe3XI1WcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10,shuffle=True,random_state=42)\n",
        "rnd_forest_train =cross_val_score(rnd_forest, x_train, y_train, cv=kfold, scoring='accuracy')\n",
        "pd.DataFrame(rnd_forest_train,columns=['Scores'])\n",
        "print(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (rnd_forest_train.mean()*100.0, rnd_forest_train.std()*100.0))\n",
        "rnd_forest_test =cross_val_score(rnd_forest, x_test, y_test, cv=kfold, scoring='accuracy')\n",
        "pd.DataFrame(rnd_forest_test,columns=['Scores'])\n",
        "print(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (rnd_forest_test.mean()*100.0, rnd_forest_test.std()*100.0))\n"
      ],
      "metadata": {
        "id": "jlLMfJ5C2Eeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "# Initialize the Random Forest Classifier\n",
        "rfc = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV with the Random Forest Classifier and parameter grid\n",
        "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)"
      ],
      "metadata": {
        "id": "7eHod09O4xU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "accuracy = best_model.score(x_test, y_test)\n",
        "print(\"Accuracy on Test Set:\", accuracy)"
      ],
      "metadata": {
        "id": "mbrYAxKJ5n1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "FCcRzviS6BaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1_pred=dt.predict(x_test)\n",
        "y1_pred"
      ],
      "metadata": {
        "id": "o-2BIdw06Ye3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accurecy\",accuracy_score(y_test,y1_pred))"
      ],
      "metadata": {
        "id": "OWzPL3On6ghZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ensemble model\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "ensemble = VotingClassifier(estimators=[('rf', rnd_forest), ('dt', dt)], voting='hard')\n",
        "ensemble.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "tnYv9QB-6-fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y2_pred=ensemble.predict(x_test)\n",
        "y2_pred"
      ],
      "metadata": {
        "id": "5rmfhbF37LvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test,y2_pred)"
      ],
      "metadata": {
        "id": "wqecLtKQ7Uhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read descriptions\n",
        "description=pd.read_csv(\"symptom_Description.csv\")\n",
        "description.head(10)"
      ],
      "metadata": {
        "id": "Oaaazrvg2VUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precaution = pd.read_csv(\"symptom_precaution.csv\")\n",
        "precaution.head(10)"
      ],
      "metadata": {
        "id": "ZcmyYAmb4TXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras scikit-learn"
      ],
      "metadata": {
        "id": "dHcWxv6AESxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install --upgrade keras scikit-learn\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QnwSv2hUEQq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, InputLayer, LeakyReLU, Dropout\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "asUpg0onDRvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(y_train))\n",
        "num_classes\n"
      ],
      "metadata": {
        "id": "K6k3K7juF17G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the label encoder and transform the labels\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Determine the number of classes\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5B0Mf4BNF7_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert to one-hot encoding\n",
        "y_train_cat = to_categorical(y_train_encoded, num_classes=num_classes)\n",
        "y_test_cat = to_categorical(y_test_encoded, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "fvQOUfMrGM72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(epochs, batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(x_train.shape[1],)))\n",
        "    model.add(Dense(128))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train_cat, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=0)\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_test_classes = np.argmax(y_test_cat, axis=1)\n",
        "\n",
        "    return accuracy_score(y_test_classes, y_pred_classes)\n"
      ],
      "metadata": {
        "id": "-AvSaWKcHVi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = train_and_evaluate_model(epochs=100, batch_size=32)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "FmnEgK8MHeNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save\n",
        "import joblib\n",
        "joblib.dump(rnd_forest,'disease.pkl')\n"
      ],
      "metadata": {
        "id": "g4VVC0uR4m-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load\n",
        "model = joblib.load('disease.pkl')"
      ],
      "metadata": {
        "id": "3BQsXJkE7lai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can use the model to make predictions\n",
        "# Define the example input\n",
        "example_input = [[1, 2, 3, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
        "\n",
        "# Make a prediction using the loaded model\n",
        "prediction = model.predict(example_input)\n",
        "\n",
        "# Print the prediction\n",
        "print(\"Prediction:\", prediction)"
      ],
      "metadata": {
        "id": "-eOygMPB7qg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predd(x, S1, S2, S3, S4, S5, S6, S7, S8, S9, S10, S11, S12, S13, S14, S15, S16, S17):\n",
        "    # List of symptoms\n",
        "    psymptoms = [S1, S2, S3, S4, S5, S6, S7, S8, S9, S10, S11, S12, S13, S14, S15, S16, S17]\n",
        "\n",
        "    # Convert symptoms to weights using df1\n",
        "    a = np.array(df1[\"Symptom\"])\n",
        "    b = np.array(df1[\"weight\"])\n",
        "\n",
        "    # Replace symptoms with weights\n",
        "    for j in range(len(psymptoms)):\n",
        "        if psymptoms[j] in a:\n",
        "            psymptoms[j] = b[np.where(a == psymptoms[j])[0][0]]\n",
        "        else:\n",
        "            psymptoms[j] = 0  # Default to 0 if symptom is not found\n",
        "\n",
        "    # Convert list to array and reshape\n",
        "    psy = [psymptoms]\n",
        "    psy = np.array(psy, dtype=float)  # Ensure all values are floats\n",
        "\n",
        "    # Predict\n",
        "    pred2 = x.predict(psy)\n",
        "\n",
        "    # Retrieve disease description\n",
        "    disp = description[description['Disease'] == pred2[0]]\n",
        "    disp = disp.values[0][1] if not disp.empty else \"Description not found\"\n",
        "\n",
        "    # Retrieve recommendations\n",
        "    recomnd = precaution[precaution['Disease'] == pred2[0]]\n",
        "    precuation_list = []\n",
        "    if not recomnd.empty:\n",
        "        c = np.where(precaution['Disease'] == pred2[0])[0][0]\n",
        "        for i in range(1, len(precaution.iloc[c])):\n",
        "            precuation_list.append(precaution.iloc[c, i])\n",
        "\n",
        "    # Print results\n",
        "    print(\"The Disease Name: \", pred2[0])\n",
        "    print(\"The Disease Description: \", disp)\n",
        "    print(\"Recommended Things to do at home: \")\n",
        "    for i in precuation_list:\n",
        "        print(i)\n",
        "# Define symptoms\n",
        "S1 = 'fever'\n",
        "S2 = 'cough'\n",
        "S3 = 'headache'\n",
        "S4 = 'fatigue'\n",
        "S5 = 'muscle pain'\n",
        "# Add more symptoms as needed\n",
        "\n",
        "# Load your model and dataframes\n",
        "model = joblib.load('disease.pkl')  # Replace with your actual model loading method\n",
        "\n",
        "# Call the function\n",
        "predd(model, S1, S2, S3, S4, S5, None, None, None, None, None, None, None, None, None, None, None, None)\n"
      ],
      "metadata": {
        "id": "YjnqP02H8Zy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define symptoms\n",
        "S1 = 'fever'\n",
        "S2 = 'cough'\n",
        "S3 = 'sore throat'\n",
        "S4 = 'muscle pain'\n",
        "S5 = 'nausea'\n",
        "\n",
        "model = joblib.load('disease.pkl')\n",
        "\n",
        "# Call the function\n",
        "predd(model, S1, S2, S3, S4, S5,None, None, None, None, None, None, None, None, None, None, None, None )\n",
        "\n"
      ],
      "metadata": {
        "id": "Rtn-upAR9Soc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def predd(model, S1, S2, S3, S4, S5, S6=None, S7=None, S8=None, S9=None, S10=None,\n",
        "          S11=None, S12=None, S13=None, S14=None, S15=None, S16=None, S17=None):\n",
        "    # Define symptoms list with given inputs\n",
        "    psymptoms = [S1, S2, S3, S4, S5, S6, S7, S8, S9, S10, S11, S12, S13, S14, S15, S16, S17]\n",
        "\n",
        "    # Assuming df1 is a DataFrame with symptom names and their weights\n",
        "    a = np.array(df1[\"Symptom\"])\n",
        "    b = np.array(df1[\"weight\"])\n",
        "\n",
        "    # Replace symptoms with their weights\n",
        "    for j in range(len(psymptoms)):\n",
        "        if psymptoms[j] in a:\n",
        "            index = np.where(a == psymptoms[j])[0][0]\n",
        "            psymptoms[j] = b[index]\n",
        "        else:\n",
        "            psymptoms[j] = 0  # Handle symptoms not found in the DataFrame\n",
        "\n",
        "    # Prepare the feature array for prediction\n",
        "    psy = np.array([psymptoms])\n",
        "\n",
        "    # Make a prediction\n",
        "    pred2 = model.predict(psy)\n",
        "\n",
        "    # Assuming description and precaution are DataFrames with disease descriptions and recommendations\n",
        "    disease = pred2[0]  # The predicted class (index or label)\n",
        "\n",
        "    # Get disease description\n",
        "    disp = description[description['Disease'] == disease]\n",
        "    if not disp.empty:\n",
        "        disp = disp.values[0][1]\n",
        "    else:\n",
        "        disp = \"Description not found.\"\n",
        "\n",
        "    # Get recommended actions\n",
        "    recomnd = precaution[precaution['Disease'] == disease]\n",
        "    if not recomnd.empty:\n",
        "        c = np.where(precaution['Disease'] == disease)[0][0]\n",
        "        precaution_list = [precaution.iloc[c, i] for i in range(1, len(precaution.columns))]\n",
        "    else:\n",
        "        precaution_list = [\"Recommendations not found.\"]\n",
        "\n",
        "    # Print the results\n",
        "    print(\"The Disease Name: \", disease)\n",
        "    print(\"The Disease Description: \", disp)\n",
        "    print(\"Recommended Things to do at home: \")\n",
        "    for item in precaution_list:\n",
        "        print(item)\n",
        "\n"
      ],
      "metadata": {
        "id": "hZ1XecH6IFi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define your variables\n",
        "n_groups = 2\n",
        "algorithms = 'Random Forest'\n",
        "train_accuracy = rnd_forest_train.mean() * 100.0\n",
        "test_accuracy = rnd_forest_test.mean() * 100.0\n",
        "standard_deviation = rnd_forest_test.std() * 100.0"
      ],
      "metadata": {
        "id": "3Mc6u0VOMClo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sympList=df1[\"Symptom\"].to_list()\n",
        "predd(rnd_forest,sympList[2],sympList[6],sympList[10],sympList[55],0,0,0,0,0,0,0,0,0,0,0,0,0)"
      ],
      "metadata": {
        "id": "Fy2SpyjIMOw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define symptoms\n",
        "S1 = 'stomach pain'\n",
        "S2 = 'acidity'\n",
        "S3 = 'ulcers on tongue'\n",
        "S4 = 'vomiting'\n",
        "S5 = 'caugh'\n",
        "\n",
        "model = joblib.load('disease.pkl')\n",
        "\n",
        "# Call the function\n",
        "predd(model, S1, S2, S3, S4, S5,None, None, None, None, None, None, None, None, None, None, None, None )\n"
      ],
      "metadata": {
        "id": "7qogxSZHMee8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zgLiY3WtMxwV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}